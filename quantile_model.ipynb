{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from numpy import ndarray\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class DataLoader(object):\n",
    "\n",
    "    cols = [\"be_me\", \"ret_12_1\", \"market_equity\", \"ret_1_0\", \"rvol_252d\", \"beta_252d\", \"qmj_safety\", \"rmax1_21d\",\n",
    "            \"chcsho_12m\", \"ni_me\", \"eq_dur\", \"ret_60_12\", \"ope_be\", \"gp_at\", \"ebit_sale\", \"at_gr1\", \"sale_gr1\",\n",
    "            \"at_be\", \"cash_at\", \"age\", \"z_score\"]\n",
    "\n",
    "    cols1 = [\"permno\", \"date\", \"ret_exc_lead1m\", \"be_me\", \"ret_12_1\", \"market_equity\", \"ret_1_0\", \"rvol_252d\",\n",
    "             \"beta_252d\", \"qmj_safety\", \"rmax1_21d\", \"chcsho_12m\", \"ni_me\", \"eq_dur\", \"ret_60_12\", \"ope_be\",\n",
    "             \"gp_at\", \"ebit_sale\", \"at_gr1\", \"sale_gr1\", \"at_be\", \"cash_at\", \"age\", \"z_score\"]\n",
    "\n",
    "    def __init__(self, csv_file_path: str):\n",
    "        self.data: DataFrame = pd.read_csv(csv_file_path)\n",
    "\n",
    "    def slice(self, start: int, end: int) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Slice a dataload to look for data within the certain time period\n",
    "        :param start: slice start, inclusive. In form of YYYYMMDD (19900000)\n",
    "        :param end: slice end, exclusive.\n",
    "        :return: a pandas dataframe after slicing\n",
    "        \"\"\"\n",
    "        data = self.data[(self.data[\"date\"] >= start) & (self.data[\"date\"] < end)]\n",
    "        data = data.dropna(subset=['me', 'ret_exc_lead1m'])\n",
    "        # exclude nano caps\n",
    "        data = data.loc[data['size_grp'] != 'nano']\n",
    "        # delete observation with more than 5 out of the 21 characteristics missing\n",
    "        data[\"missing_num\"] = data[DataLoader.cols].isna().sum(1)\n",
    "        data = data.loc[data['missing_num'] <= 5]\n",
    "\n",
    "        # impute the missing characteristics by replacing them with the cross-sectional median\n",
    "        for i in DataLoader.cols:\n",
    "            data[i] = data[i].astype(float)\n",
    "            data[i] = data[i].fillna(data.groupby('date')[i].transform('median'))\n",
    "\n",
    "        data = data[DataLoader.cols1]\n",
    "        data = data.dropna()\n",
    "\n",
    "        # rank transformation\n",
    "        # each characteristic is transformed into the cross-sectional rank\n",
    "        for i in DataLoader.cols:\n",
    "            data[i] = data.groupby(\"date\")[i].rank(pct=True)\n",
    "\n",
    "        data.sort_values(by=['date', 'permno'], inplace=True)\n",
    "\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def get_x(df: DataFrame) -> ndarray: return df[DataLoader.cols].to_numpy()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_y(df: DataFrame) -> ndarray: return df[\"ret_exc_lead1m\"].to_numpy()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_y_quantiles(df: DataFrame) -> ndarray:\n",
    "        raw_y = df[\"ret_exc_lead1m\"].to_numpy()\n",
    "        def calculate_single_quantile_fn(y):\n",
    "            return (raw_y[:] < y).sum() / raw_y.shape\n",
    "        calculate_single_quantile = np.vectorize(calculate_single_quantile_fn)\n",
    "        return np.apply_along_axis(calculate_single_quantile, 0, raw_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/29/l7nrj2kj79s5n10vdwh2ywnc0000gn/T/ipykernel_93092/334611359.py:12: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.data: DataFrame = pd.read_csv(csv_file_path)\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(\"data/usa.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(-11.389144479935478, 0.001)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from numpy import ndarray\n",
    "try:\n",
    "    from sklearn import r2_score\n",
    "except ImportError:\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "class LassoQuantileModel(object):\n",
    "\n",
    "    def __init__(self, data_loader: DataLoader, lambda_value: float):\n",
    "        self.data_loader = data_loader\n",
    "        self.lambda_value = lambda_value\n",
    "        self.beta = np.zeros((len(self.data_loader.cols)))\n",
    "        self.intercept = 0.0\n",
    "        self.objective = 0.0\n",
    "\n",
    "    def _cp_loss_fn(self, X: np.array, Y: np.array, beta: cp.Variable, intercept: cp.Variable):\n",
    "        raw_predicted_y = X @ beta + intercept\n",
    "        return (1.0 / X.shape[0]) * (cp.norm2(raw_predicted_y - Y)**2)\n",
    "\n",
    "    def _objective_fn(self, X, Y, beta, intercept, lambda_value):\n",
    "        return self._cp_loss_fn(X, Y, beta, intercept) + lambda_value * cp.norm1(beta)\n",
    "\n",
    "        # train with sklearn\n",
    "    def fit(self, start: int, end: int) -> None:\n",
    "        df = self.data_loader.slice(start, end)\n",
    "        x_train = self.data_loader.get_x(df)\n",
    "        y_train = self.data_loader.get_y_quantiles(df)\n",
    "\n",
    "        beta = cp.Variable(len(self.data_loader.cols))\n",
    "        intercept = cp.Variable(1)\n",
    "        problem = cp.Problem(cp.Minimize(self._objective_fn(x_train, y_train, beta, intercept, self.lambda_value)))\n",
    "        problem.solve(solver=cp.SCS)\n",
    "\n",
    "        self.beta = beta.value\n",
    "        self.intercept = intercept.value\n",
    "        self.objective = problem.objective\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, data_loader: DataLoader,\n",
    "                 train_start: int,\n",
    "                 train_end: int,\n",
    "                 validate_start: int,\n",
    "                 validate_end: int,\n",
    "                 lambda_values: list):\n",
    "        \"\"\"\n",
    "        Tune hyperparameters using a validation set\n",
    "        :param validate_end:\n",
    "        :param validate_start:\n",
    "        :param train_end:\n",
    "        :param train_start:\n",
    "        :param data_loader: DataLoader object\n",
    "        :param lambda_values: List of lambda values to conduct grid search\n",
    "        \"\"\"\n",
    "        validate_df = data_loader.slice(validate_start, validate_end)\n",
    "        y_validate = data_loader.get_y(validate_df)\n",
    "\n",
    "        best_model = None\n",
    "        best_lambda = None\n",
    "        best_r2 = -float('inf')\n",
    "\n",
    "        for lambda_val in lambda_values:\n",
    "            model = LassoQuantileModel(data_loader, lambda_val)\n",
    "            model.fit(train_start, train_end)\n",
    "            y_pred = model.predict(validate_start, validate_end)\n",
    "\n",
    "            r2 = r2_score(y_validate, y_pred)  # Calculate R-squared\n",
    "\n",
    "            if r2 > best_r2:\n",
    "                best_lambda = lambda_val\n",
    "                best_r2 = r2\n",
    "                best_model = model\n",
    "\n",
    "        return best_model, best_r2, best_lambda\n",
    "\n",
    "    # def _to_quantiles(self, raw_y: np.array) -> np.array:\n",
    "    #     def calculate_single_quantile_fn(y):\n",
    "    #         return (raw_y[:] < y).sum() / raw_y.shape\n",
    "    #     calculate_single_quantile = np.vectorize(calculate_single_quantile_fn)\n",
    "    #     return np.apply_along_axis(calculate_single_quantile, 0, raw_y)\n",
    "\n",
    "    def _to_quantiles(self, raw_y: np.array) -> np.array:\n",
    "        max = raw_y.max()\n",
    "        min = raw_y.min()\n",
    "        rng = max - min\n",
    "        return (raw_y - min) / rng\n",
    "\n",
    "    def predict(self, start: int, end: int) -> ndarray:\n",
    "        # Slice the data for the prediction period\n",
    "        df = self.data_loader.slice(start, end)\n",
    "        x_pred = self.data_loader.get_x(df)\n",
    "        raw_y_pred = x_pred @ self.beta + self.intercept\n",
    "        return self._to_quantiles(raw_y_pred)\n",
    "\n",
    "    def evaluate(self, start: int, end: int) -> float:\n",
    "        \"\"\"\n",
    "        Give evaluation metric of a trained/fitted model on a given test/validation period\n",
    "        :param start: period start year\n",
    "        :param end: period end year\n",
    "        :return: an evaluation metric as floating number\n",
    "        \"\"\"\n",
    "        df = self.data_loader.slice(start, end)\n",
    "        y_actual = self.data_loader.get_y_quantiles(df)\n",
    "        y_pred = self.predict(start, end)\n",
    "        # Calculate R-squared\n",
    "        r2 = r2_score(y_actual, y_pred)\n",
    "        return r2\n",
    "\n",
    "# model = LassoQuantileModel(data, 0.001)\n",
    "# model.fit(19800101, 19950101)\n",
    "# model.evaluate(19950101, 20000101)\n",
    "\n",
    "best_model, best_r2, best_lambda = LassoQuantileModel.validate(data, 19800101, 19950101, 19950101, 20000101, [0, 0.0000001, 0.00001, 0.001])\n",
    "best_r2, best_lambda"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.17552299445653174"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(data.get_y_quantiles(data.slice(20000101, 20010101)), best_model.predict(20000101, 20010101))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.19097305, 0.44310458, 0.80138028, ..., 0.60767947, 0.55999583,\n       0.73098021])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get_y_quantiles(data.slice(20000101, 20010101))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.44756141, 0.50342833, 0.40124911, ..., 0.63957787, 0.77478834,\n       0.3178959 ])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(20000101, 20010101)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
